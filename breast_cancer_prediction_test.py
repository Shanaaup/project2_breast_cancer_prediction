# -*- coding: utf-8 -*-
"""Breast_Cancer_Prediction_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gy5h3v8uJWodxQlJYSbQmwNn9JIH_OvZ

# Breast Cancer Prediction Project

Welcome to the Breast Cancer Prediction project! üéØ

In this beginner-friendly notebook, we'll walk through a step-by-step machine learning pipeline to predict whether a tumor is malignant or benign based on various features.

## üîç Objective

Our goal is to build a machine learning model that can accurately predict whether a tumor is **malignant (M)** or **benign (B)** based on a set of measurements.

We'll use the dataset `Cancer_Data.csv` for this purpose.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

"""## üì• Step 1: Load the Dataset"""

from google.colab import files
uploaded = files.upload()



"""## üîç Step 2: Explore the Dataset"""

import pandas as pd

# Replace 'yourfile.csv' with the actual filename you uploaded
df = pd.read_csv("Cancer_Data.csv")
df.head()



df.shape  # (rows, columns)
df.columns
df.dtypes

"""## üßπ Step 3: Clean the Data

We'll remove any unnecessary columns and handle missing values.
"""

# Drop the 'Unnamed: 32' column and 'id'
df.drop(['Unnamed: 32','id'],axis=1,inplace=True)



"""## üìä Step 4: Visualize the Data"""

import matplotlib.pyplot as plt
import seaborn as sns
sns.countplot(x='diagnosis',data=df)
plt.title('Distribution of Radius Mean by Diagnosis')
plt.show()

"""## ‚öôÔ∏è Step 5: Preprocess the Data"""

# Convert diagnosis column to 0 (benign) and 1 (malignant)
df['diagnosis'] = df['diagnosis'].map({'B': 0, 'M': 1})


# Split features and labels

# Drop diagnosis to get features
X = df.drop('diagnosis', axis=1)

# Target variable
y = df['diagnosis']


# Split into training and testing sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)


# Scale the features

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# Fit only on training data, then transform both
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""## ü§ñ Step 6: Train a Machine Learning Model"""

# Use Logistic Regression
from sklearn.linear_model import LogisticRegression

# Initialize the model
model = LogisticRegression()
model.fit(X_train_scaled, y_train)
y_pred = model.predict(X_test_scaled)

"""## üß™ Step 7: Evaluate the Model"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))

# Classification report
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

from google.colab import drive
drive.mount('/content/drive')

"""## ‚úÖ Conclusion

Awesome work! üéâ

You've successfully built a breast cancer prediction model using Logistic Regression. You explored the data, cleaned it, visualized it, trained a model, and evaluated its performance.

### üöÄ Next Steps
- Try different models like RandomForest or SVM
- Perform feature selection
- Tune hyperparameters for better accuracy
"""